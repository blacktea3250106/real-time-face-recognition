{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-----------------------\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, concatenate\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Dense, Activation, Lambda, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from model import create_model #research-papers/facenet\n",
    "#from os import listdir\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#-----------------------\n",
    "face_detector = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\",\"res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facenet model built.\n",
      "Facenet weights built.\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(\"Facenet model built.\")\n",
    "model.load_weights('nn4.small2.v1.h5') #research-papers/facenet\n",
    "print(\"Facenet weights built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    if type(img) == type('str'):\n",
    "        img = cv2.imread(img)\n",
    "        img = ssd_getDetectFace(img)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convet grayscale\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        #img = preprocess_input(img) ## [-1, 1]\n",
    "        img /= 255 # [0, 1]\n",
    "    else:\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convet grayscale\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        #img = preprocess_input(img) ## [-1, 1]\n",
    "        img /= 255  # [0, 1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance\n",
    "def findCosineDistance(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_detectFace(img):\n",
    "    \n",
    "    target_size = (300, 300)\n",
    "    \n",
    "    img = cv2.resize(img, target_size)\n",
    "\n",
    "    imageBlob = cv2.dnn.blobFromImage(img)\n",
    "\n",
    "    face_detector.setInput(imageBlob)\n",
    "    detections = face_detector.forward()\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_getDetectFace(img):\n",
    "    ssd_labels = [\"img_id\", \"is_face\", \"confidence\", \"left\", \"top\", \"right\", \"bottom\"]\n",
    "\n",
    "    target_size = (300, 300)\n",
    "\n",
    "    base_img = img.copy() #we will restore base_img to img later\n",
    "\n",
    "    original_size = img.shape\n",
    "\n",
    "    img = cv2.resize(img, target_size)\n",
    "\n",
    "    aspect_ratio_x = (original_size[1] / target_size[1])\n",
    "    aspect_ratio_y = (original_size[0] / target_size[0])\n",
    "\n",
    "    imageBlob = cv2.dnn.blobFromImage(image = img)\n",
    "    \n",
    "    face_detector = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\",\"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "    face_detector.setInput(imageBlob)\n",
    "    detections = face_detector.forward()\n",
    "\n",
    "    detections_df = pd.DataFrame(detections[0][0], columns = ssd_labels)\n",
    "\n",
    "    detections_df = detections_df[detections_df['is_face'] == 1] #0: background, 1: face\n",
    "    detections_df = detections_df[detections_df['confidence'] >= 0.90]\n",
    "\n",
    "    detections_df['left'] = (detections_df['left'] * 300).astype(int)\n",
    "    detections_df['bottom'] = (detections_df['bottom'] * 300).astype(int)\n",
    "    detections_df['right'] = (detections_df['right'] * 300).astype(int)\n",
    "    detections_df['top'] = (detections_df['top'] * 300).astype(int)\n",
    "    \n",
    "    if detections_df.shape[0] > 0:\n",
    "\n",
    "        #TODO: sort detections_df\n",
    "\n",
    "        #get the first face in the image\n",
    "        instance = detections_df.iloc[0]\n",
    "\n",
    "        left = int(instance[\"left\"] * aspect_ratio_x)\n",
    "        right = int(instance[\"right\"] * aspect_ratio_x)\n",
    "        bottom = int(instance[\"bottom\"] * aspect_ratio_y)\n",
    "        top = int(instance[\"top\"] * aspect_ratio_y)\n",
    "\n",
    "        detected_face = base_img[top:bottom, left:right]\n",
    "        \n",
    "        #cv2.rectangle(img, (left, top), (right, bottom),(10, 10, 255), 3)\n",
    "        \n",
    "        return detected_face[:,:,::-1] #convert RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE_ALBUM_2023831_230831_1.jpg\n",
      "LINE_ALBUM_2023831_230831_10.jpg\n",
      "LINE_ALBUM_2023831_230831_11.jpg\n",
      "LINE_ALBUM_2023831_230831_12.jpg\n",
      "LINE_ALBUM_2023831_230831_13.jpg\n",
      "LINE_ALBUM_2023831_230831_14.jpg\n",
      "LINE_ALBUM_2023831_230831_15.jpg\n",
      "LINE_ALBUM_2023831_230831_2.jpg\n",
      "LINE_ALBUM_2023831_230831_3.jpg\n",
      "LINE_ALBUM_2023831_230831_4.jpg\n",
      "LINE_ALBUM_2023831_230831_5.jpg\n",
      "LINE_ALBUM_2023831_230831_6.jpg\n",
      "LINE_ALBUM_2023831_230831_7.jpg\n",
      "LINE_ALBUM_2023831_230831_8.jpg\n",
      "LINE_ALBUM_2023831_230831_9.jpg\n",
      "977.png\n",
      "d8a24b317b1d544cf1fefc16628ef0a7.png\n",
      "gettyimages-139369178-594x594.jpg\n",
      "gettyimages-490703338.jpg\n",
      "gettyimages-86146687-612x612.jpg\n",
      "gettyimages-93243663-612x612.jpg\n",
      "i.png\n",
      "Kobe_Bryant_2014.jpg\n",
      "Kobe_Bryant_2015.jpg\n",
      "phpflly88.jpg\n",
      "16752529896605.jpg\n",
      "16852041551656.jpg\n",
      "2544.png\n",
      "504c63a03d8a751a5cbeda0bc064306bb4-lebron-james.rsquare.w700.png\n",
      "c05041402158dc67fcd77e5512d0bed5.png\n",
      "i_8e_7f_1e_lebron-james.png\n",
      "LeBron-1040x572.jpg\n",
      "lebron-james-b73c66eb3444477c8896a44a3e39b671.jpg\n",
      "LeBron_James_(51959977144)_(cropped2).jpg\n",
      "LeBron_James_-_51959723161_(cropped).png\n",
      "employee representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "employees = []\n",
    "\n",
    "db_path = '.\\database'\n",
    "\n",
    "for r, d, f in os.walk(db_path): # r=root, d=directories, f = files\n",
    "    for file in f:\n",
    "        print(file)\n",
    "        img = preprocess_image(r + \"\\\\\" + file)\n",
    "        \n",
    "        representation = model.predict(img)[0,:]\n",
    "        name = r.replace(db_path,\"\").replace(\"\\\\\",\"\")\n",
    "        \n",
    "        employees.append([representation,name])\n",
    "\n",
    "print(\"employee representations retrieved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam\n",
    "counter = 0\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    (h, w) = np.array(img).shape[:2]\n",
    "\n",
    "    detections = ssd_detectFace(img)\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence < 0.9:\n",
    "            continue\n",
    "\n",
    "        box = detections[0, 0, i, 3:] * np.array([w, h, w, h])\n",
    "        (left, top, right, bottom) = box.astype(\"int\") #L/T/R/B\n",
    "\n",
    "        label_name = 'unknown'\n",
    "        threshold = 0.55\n",
    "\n",
    "        detected_face = img[top:bottom,left:right][:,:,::-1] #convert RGB\n",
    "        preprocess_img = preprocess_image(detected_face)\n",
    "        captured_representation = model.predict(preprocess_img)[0,:]\n",
    "        \n",
    "        for employee in employees:\n",
    "            source_representation = employee[0]\n",
    "            \n",
    "            distance = findEuclideanDistance(captured_representation, source_representation)\n",
    "\n",
    "            if distance <= threshold:\n",
    "                label_name = employee[1]\n",
    "                threshold = distance\n",
    "                \n",
    "        if label_name == 'unknown':\n",
    "            text = label_name\n",
    "        else:\n",
    "            #threshold = 0.65 -> 75\n",
    "            #threshold = 0.0 -> 100\n",
    "            score = threshold*-400/11+100 \n",
    "            text = label_name + \" {:.2f}%\".format(score)\n",
    "        \n",
    "        color = (50, 50, 200) # R(50, 50, 200) G(50, 200, 50) B(200,50,50) Y(255,200,50) B(0,200,255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 3)\n",
    "        cv2.rectangle(img, (left, top), (right, top+25), color,-1)\n",
    "        \n",
    "        #FONT_HERSHEY_SIMPLEX or FONT_HERSHEY_DUPLEX\n",
    "        \n",
    "        if(right-left < 100):\n",
    "            \n",
    "            cv2.putText(img, text, (left, top+15),cv2.FONT_HERSHEY_DUPLEX, 0.25, (255, 255, 255), 1,cv2.LINE_AA)\n",
    "        elif(right-left < 120):\n",
    "            cv2.putText(img, text, (left, top+15),cv2.FONT_HERSHEY_DUPLEX, 0.30, (255, 255, 255), 1,cv2.LINE_AA)\n",
    "        elif(right-left < 150):\n",
    "            cv2.putText(img, text, (left, top+15),cv2.FONT_HERSHEY_DUPLEX, 0.35, (255, 255, 255), 1,cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(img, text, (left, top+15),cv2.FONT_HERSHEY_DUPLEX, 0.45, (255, 255, 255), 1,cv2.LINE_AA)\n",
    "        \n",
    "        counter += 1\n",
    "        if (time.time() - start_time) != 0:\n",
    "            fps = counter / (time.time() - start_time)\n",
    "            #cv2.rectangle(img, (0, 0), (60, 25),(50, 50, 50),-1)\n",
    "            cv2.putText(img, \"FPS:{:.0f}\".format(fps), (2, 15),cv2.FONT_HERSHEY_DUPLEX, 0.45, (100, 100, 100), 1,cv2.LINE_AA)\n",
    "\n",
    "        counter = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "    cv2.imshow(\"SSD Face Detection and OpenFace Face Recognition\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"): #press q to quit\n",
    "        break\n",
    "\n",
    "#kill open cvthings\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
